{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST IN TENSORFLOW\n",
    "## IRIS DATASET\n",
    "\n",
    "Source: https://www.kaggle.com/thomascolthurst/tensorforest-on-iris/data       \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hi, everyone. I'm Thomas Colthurst, and I work on a random forest implementation called TensorForest. As the name suggests, TensorForest is built on top of TensorFlow, which makes it easy to use all the goodies that TensorFlow provides (feature preprocessing, distributed training, etc.). You can find out more about TensorForest by reading our NIPS 2017 paper.\n",
    "\n",
    "This is a simple example to show you how to use TensorForest on the Iris classification task. (TensorForest also works for regression problems, but this won't cover that.)\n",
    "\n",
    "First, let's load the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training = \n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "0   1            5.1           3.5            1.4           0.2  Iris-setosa\n",
      "2   3            4.7           3.2            1.3           0.2  Iris-setosa\n",
      "4   5            5.0           3.6            1.4           0.2  Iris-setosa\n",
      "6   7            4.6           3.4            1.4           0.3  Iris-setosa\n",
      "8   9            4.4           2.9            1.4           0.2  Iris-setosa\n",
      "Test = \n",
      "   Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Species\n",
      "1   2            4.9           3.0            1.4           0.2  Iris-setosa\n",
      "3   4            4.6           3.1            1.5           0.2  Iris-setosa\n",
      "5   6            5.4           3.9            1.7           0.4  Iris-setosa\n",
      "7   8            5.0           3.4            1.5           0.2  Iris-setosa\n",
      "9  10            4.9           3.1            1.5           0.1  Iris-setosa\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from glob import glob\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.DEBUG)\n",
    "\n",
    "all_data = pd.read_csv(\"iris.csv\")\n",
    "\n",
    "train = all_data[::2]\n",
    "test = all_data[1::2]\n",
    "\n",
    "print(\"Training = \")\n",
    "print(train[:5])\n",
    "\n",
    "print(\"Test = \")\n",
    "print(test[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I split the data into halves for training and test. Next, let's split the training data into features and labels:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training features =\n",
      "[[5.1 3.5 1.4 0.2]\n",
      " [4.7 3.2 1.3 0.2]\n",
      " [5.  3.6 1.4 0.2]\n",
      " [4.6 3.4 1.4 0.3]\n",
      " [4.4 2.9 1.4 0.2]]\n",
      "Training labels =\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "x_train = train.drop(['Species', 'Id'], axis=1).astype(np.float32).values\n",
    "label_map = {'Iris-setosa': 0, 'Iris-versicolor': 1, 'Iris-virginica': 2}\n",
    "y_train = train['Species'].map(label_map).astype(np.float32).values\n",
    "\n",
    "print(\"Training features =\")\n",
    "print(x_train[:5])\n",
    "print(\"Training labels =\")\n",
    "print(y_train[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great, now let's configure the forest. We need to specify how many classes there are, how many features, how many trees we want, and the maximum size of those trees. TensorForest will intelligently set a bunch of other training parameters based on those values. In this example, we choose to override one of those -- we say we want to split any node once it has seen 50 examples.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Params =\n",
      "{'num_trees': 50, 'max_nodes': 1000, 'bagging_fraction': 1.0, 'feature_bagging_fraction': 1.0, 'num_splits_to_consider': 10, 'max_fertile_nodes': 0, 'split_after_samples': 50, 'valid_leaf_threshold': 1, 'dominate_method': 'bootstrap', 'dominate_fraction': 0.99, 'model_name': 'all_dense', 'split_finish_name': 'basic', 'split_pruning_name': 'none', 'collate_examples': False, 'checkpoint_stats': False, 'use_running_stats_method': False, 'initialize_average_splits': False, 'inference_tree_paths': False, 'param_file': None, 'split_name': 'less_or_equal', 'early_finish_check_every_samples': 0, 'prune_every_samples': 0, 'num_classes': 3, 'num_features': 4, 'bagged_num_features': 4, 'bagged_features': None, 'regression': False, 'num_outputs': 1, 'num_output_columns': 4, 'base_random_seed': 0, 'leaf_model_type': 0, 'stats_model_type': 0, 'finish_type': 0, 'pruning_type': 0, 'split_type': 0}\n"
     ]
    }
   ],
   "source": [
    "params = tf.contrib.tensor_forest.python.tensor_forest.ForestHParams(\n",
    "  num_classes=3, num_features=4, num_trees=50, max_nodes=1000, split_after_samples=50).fill()\n",
    "\n",
    "print(\"Params =\")\n",
    "print(vars(params))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Everything is set up, so it's time to train the forest:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[WinError 5] Отказано в доступе: '/$Recycle.Bin'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-6f33a9d2aee2>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m#for f in glob(\"./*\"):\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mglob\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"/*\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m classifier = tf.contrib.tensor_forest.client.random_forest.TensorForestEstimator(\n\u001b[0;32m      6\u001b[0m     params, model_dir=\"/\")\n",
      "\u001b[1;31mPermissionError\u001b[0m: [WinError 5] Отказано в доступе: '/$Recycle.Bin'"
     ]
    }
   ],
   "source": [
    "# Remove previous checkpoints so that we can re-run this step if necessary.\n",
    "for f in glob(\"./*\"):\n",
    "    os.remove(f)\n",
    "classifier = tf.contrib.tensor_forest.client.random_forest.TensorForestEstimator(\n",
    "    params, model_dir=\"./\")\n",
    "classifier.fit(x=x_train, y=y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While the forest is training, the negative of the current average tree size is reported as the loss. (This is sort of a hack to get around the fact that random forest training isn't loss-based in the way that TensorFlow expects.)\n",
    "\n",
    "Now let's see how well this forest does on the test data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_test = \n",
      "[[4.9 3.  1.4 0.2]\n",
      " [4.6 3.1 1.5 0.2]\n",
      " [5.4 3.9 1.7 0.4]\n",
      " [5.  3.4 1.5 0.2]\n",
      " [4.9 3.1 1.5 0.1]]\n",
      "test labels =\n",
      "[0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'classifier' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-231c228cc8e1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0my_out\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_out\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'classifier' is not defined"
     ]
    }
   ],
   "source": [
    "x_test = test.drop(['Species', 'Id'], axis=1).astype(np.float32).values\n",
    "y_test = test['Species'].map(label_map).astype(np.float32).values\n",
    "\n",
    "print(\"x_test = \")\n",
    "print(x_test[:5])\n",
    "\n",
    "print(\"test labels =\")\n",
    "print(y_test[:5])\n",
    "\n",
    "y_out = list(classifier.predict(x=x_test))\n",
    "\n",
    "print(y_out[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output comes both as soft (probabilities) and hard (single class) predictions, so there are a bunch of ways you can slice and dice them. Here are a few:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-d3e4043f6ca1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mout_soft\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'classes'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mout_hard\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'probabilities'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0my\u001b[0m \u001b[1;32min\u001b[0m \u001b[0my_out\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Soft predictions:\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'y_out' is not defined"
     ]
    }
   ],
   "source": [
    "n = len(y_test)\n",
    "out_soft = list(y['classes'] for y in y_out)\n",
    "out_hard = list(y['probabilities'] for y in y_out)\n",
    "\n",
    "print(\"Soft predictions:\")\n",
    "print(out_soft[:5])\n",
    "print(\"Hard predictions:\")\n",
    "print(out_hard[:5])\n",
    "\n",
    "soft_zipped = zip(y_test, out_soft)\n",
    "hard_zipped = list(zip(y_test, out_hard))\n",
    "\n",
    "num_correct = sum(1 for p in hard_zipped if p[0] == p[1])\n",
    "print(\"Accuracy = %s\" % (num_correct / n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
